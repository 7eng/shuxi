



## 数栖平台大数据基础组件技术文档

### 一、数栖平台存储技术

数栖平台采用HDFS作为底层主存储。

#### 1.HDFS

##### 1.1基本原理

##### 1.1.1 功能

Hadoop分布式文件系统（Hadoop Distributed File System）能提供高吞吐量的数据访问，适合大规模数据集方面的应用。

##### 1.1.2 结构

> 普通HA

HDFS包含主、备NameNode和多个DataNode。

HDFS是一个Master/Slave的结构，在Master上运行NameNode，而在每一个Slave上运行DataNode。

NameNode和DataNode之间的通信都是建立在TCP/IP的基础之上的。NameNode和DataNode都是设计成可以部署在运行Linux的服务器上。

> HA 模式


> 模块功能描述

| 角色                      | 描述                                       |
| ----------------------- | ---------------------------------------- |
| NameNode                | 用于管理文件系统的命名空间、目录结构、元数据信息以及提供备份机制等，分为：  <br><br>Active NameNode：管理文件系统的命名空间、维护文件系统的目录结构树以及元数据信息；记录写入的每个“数据块”与其归属文件的对应关系。 <br> <br>Standby NameNode：对Active NameNode进行监控；对Active NameNode中的数据进行备份；随时准备在Active NameNode出现异常时接管其服务。 |
| DataNode                | 用于存储每个文件的“数据块”数据，并且会周期性的向NameNode报告该DataNode的存放情况。 |
| DFSZKFailoverController | HA配置了一个zookeeper集群，用于ZKFC（DFSZKFailoverController）故障转移，当Active NameNode挂掉了，DFSZKFailoverController会自动切换Standby NameNode为standby状态 。 |
| JournalNode             | 主备NameNode之间通过一组JournalNode同步元数据信息，一条数据只要成功写入多数JournalNode即认为写入成功。通常配置奇数个JournalNode 。 |

##### 1.1.3原理

在HDFS内部，一个文件其实分成一个或多个“数据块”，这些“数据块”存储在DataNode集合里，NameNode负责保管和管理所有的HDFS元数据。客户端连接到NameNode，执行文件系统的“命名空间”操作，例如打开、关闭、重命名文件和目录，同时决定“数据块”到具体DataNode节点的映射。DataNode在NameNode的指挥下进行“数据块”的创建、删除和复制。另外客户端连接到DataNode，执行读写用户数据操作。



![HDFS](images/image-basic/1-HDFS.png)

##### 1.1.4 与其他组件的关系

- HDFS和HBase的配合关系

HBase是Apache的Hadoop项目的子项目，HBase利用Hadoop HDFS作为其文件存储系统。HBase位于结构化存储层，Hadoop HDFS为HBase提供了高可靠性的底层存储支持。HBase中的所有数据文件都可以存储在Hadoop HDFS文件系统上，除了HBase产生的一些日志文件。

- MapReduce和HDFS的配合关系

HDFS是hadoop 分布式文件系统，具有高容错性的特点，可以用来部署在低廉的硬件上，它提供了高吞吐量的特性，用来访问应用程序的数据，适合有超大数据集的应用程序。
而MapReduce是一种编程模型，用于大数据集（大于1TB）的并行运算。在MapReduce程序中计算的数据可以来自多个数据源，如local File、HDFS、数据库等。最常用的是HDFS，可以利用HDFS的高吞吐性能读取大规模的数据进行计算。同时在计算完成后，也可以将数据存储到HDFS。
对比Spark，MapReduce读取HDFS数据或者存储数据到HDFS中都相对简单。当MapReduce运行Task时，会基于用户编写的业务逻辑进行读取或存储数据。

- Spark和HDFS的配合关系

通常，Spark中计算的数据可以来自多个数据源，如local File、HDFS等。最常用的是HDFS，可以一次读取大规模的数据进行并行计算。在计算完成后，也可以将数据存储到HDFS。



##### 1.1.5 参考文档：

http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html

#### 2.Yarn

##### 2.1 基本原理

##### 2.1.1 功能

YARN是Hadoop 2.0中的资源管理系统，它是一个通用的资源模块，可以为各类应用程序进行资源管理和调度。YARN不仅仅局限于MapReduce一种框架使用，也可以供其他框架使用，比如Tez、Spark、Storm等。YARN类似于几年前的资源管理系统Mesos和更早的Torque。由于YARN的通用性，下一代的MapReduce核心已经从简单的支持单一应用的计算框架MapReduce转移到通用的资源管理系统YARN。



##### 2.2.2 结构

YARN模型主要由ResourceManager、ApplicationMaster和NodeManager组成
![YARN](images/image-basic/2-YARN.png)



| 角色                    | 描述                                       |
| --------------------- | ---------------------------------------- |
| Client                | YARN application客户端，可以通过客户端向ResourceManager提交任务，查询application运行状态等。 |
| ResourceManager(RM)   | 集群的资源管理器，基于应用程序对资源的需求进行调度。资源管理器提供一个调度策略的插件，它负责将集群资源分配给多个队列和应用程序。调度插件可以基于现有的能力调度和公平调度模型。 |
| NodeManager（NM）       | 负责执行应用程序的容器，同时监控应用程序的资源使用情况（CPU，内存，硬盘，网络）并且向ResourceManager汇报。 |
| ApplicationMaster(AM) | 即图中的App Mstr，负责相应的调度和协调，结合从ResourceManager获得的资源和NodeManager协同工作来运行和监控任务。 |
| Container             | 作为资源隔离，当前仅仅提供java虚拟机CPU、内存的隔离。           |



##### 2.2.3 原理

新的Hadoop MapReduce框架命名为MapReduceV2或者叫YARN。YARN主要分为ResourceManager、ApplicationMaster与NodeManager三个部分。

- ResourceManager是一个中心的服务，负责调度、启动每一个Job所属的ApplicationMaster、同时监控ApplicationMaster的运行情况。ResourceManager负责作业与资源的调度，并接收JobSubmitter提交的作业，按照作业的上下文(Context)信息，以及从NodeManager收集来的状态信息，启动调度过程，分配一个Container作为ApplicationMaster。
- NodeManager功能比较专一，就是负责Container状态的维护，并向ResourceManager保持心跳。
- ApplicationMaster负责一个Job生命周期内的所有工作，类似MapReduceV1中JobTracker。但注意每一个Job（不是每一种）都有一个ApplicationMaster，它可以运行在ResourceManager以外的机器上。



##### 2.2.4 与组件的关系



##### Spark和YARN的配合关系

Spark的计算调度方式，可以通过YARN的模式实现。Spark享受YARN集群提供丰富的计算资源，将任务分布式的运行起来。Spark on YARN 分两种模式：yarn-cluster和yarn-client。

##### MapReduce和YARN的配合关系

MRv2（MapReduce v2）具有与MRv1相同的编程模型和数据处理引擎，唯一不同的是运行时环境。MRv2是在MRv1上经过加工之后，运行于资源管理框架YARN之上的计算框架MapReduce。它的运行环境不再由JobTracker和TaskTracker等服务组成，而是变为通用的资源管理系统YARN和作业控制进程ApplicationMaster，其中，YARN负责资源管理调度，而ApplicationMaster仅负责一个作业的管理。

简而言之，MapReduce（MRv2）是运行在YARN之上的一个批处理的计算框架。


### 二、数栖平台离线计算及调度

 

#### 3.Hive

##### 3.1基本原理

##### 3.1.1 功能

##### 3.1.2 结构

##### 3.1.3 原理

##### 3.1.4 与组件的关系

 



#### Spark & Spark SQL

##### 基本原理

###### 功能

Spark是基于内存进行计算的分布式计算框架。在迭代计算的场景下，数据处理过程中的数据都会存储在内存中，从而避免了MapReduce计算框架中的问题。Spark能够使用Hadoop HDFS，使用户能够快速的从MapReduce切换到Spark计算平台上去；并且提供比MapReduce高10到100倍的性能。Spark作为计算引擎，还支持小批量流式处理、离线批处理、SQL查询、数据挖掘，避免用户在这几类不同的系统中加载同一份数据带来的存储和性能上的开销。

Spark的特点如下：

- 支持分布式内存计算
- 支持迭代式的计算
- 兼容Hadoop系统文件读写方式
- 计算过程容错
- 支持多种语言开发应用(Scala/Java/Python)
- 计算能力线性扩展

###### 结构



![Spark](images/image-basic/SPARK.jpg)

| 角色              | 描述                                       |
| --------------- | ---------------------------------------- |
| Cluster Manager | 集群管理器。Spark支持多种集群管理器，Spark自带的standalone集群管理器、Mesos或YARN。 |
| Driver Program  | Spark应用程序运行时包含一个Driver进程，也是应用程序的主进程，负责应用程序的解析、生成Stage并调度Task到Executor上。 |
| Executor        | 即真正执行应用程序的地方，一个集群一般包含多个Executor，每个Executor接收Driver的命令Launch Task，一个Executor可以执行一到多个Task。 |
| Master Node     | 集群的主节点，负责接收客户端提交的作业，管理Worker，并命令Worker启动Driver和Executor。 |
| Work Node       | 负责运行集群中Spark的应用程序。负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令。 |
| SparkContext    | 面向用户的Spark程序入口，是Spark应用程序的总控，负责运用的分布执行计划和Task的调度。是用户基于业务逻辑定义的类，里面包含DAG（无回路有向图）。SparkContaxt会基于用户的业务逻辑，划分stage，并生成Task。 |
| Task            | 承载业务逻辑的运算单元，是Spark平台中可执行的最小工作单元。一个应用根据执行计划以及计算量分为多个Task。 |
| Cache           | 分布式缓存。每个Task可将结果放置于Cache，供多个后续Task读取。    |

###### 原理

##### 与组件的关系

 





#### 三、数栖平台交换技术

 

#### DataX

##### 基本原理

###### 功能

###### 结构

###### 原理

##### 与组件的关系

 

#### 四、数栖平台实时计算

 

#### Flink

##### 基本原理

###### 功能

###### 结构

###### 原理

##### 与组件的关系



 

#### 三、数栖平台交换技术

 

#### 五、数栖平台即席计算

 

#### Presto

##### 基本原理

###### 功能

###### 结构

###### 原理

##### 与组件的关系

 

六、数栖平台性能优化文档

 

 

